---
layout: post
title:  "Temporal Anti-aliasing in Flex"
date:   2019-10-19
tags: miscellaneous
permalink: /blog/:year/:month/:day/:title/
author: AJ Weeks
---

One subtle but important effect present in essentially all games that have shipped in the past two decades is anti-aliasing. Without some form of it, images have the dreaded "jaggies" and often other types of distracting visual artifacts. Many techniques have come into (and gone out of) fashion, but the most popular technique at the moment seems to be TAA, introduced by the Crytek team back in 2010. It nicely handles both screen-space aliasing (jaggies) but also temporal aliasing (fireflies), and all relatively inexpensively! The basic idea is to spread the cost of rendering the scene out multiple times (like SSAA does every frame) over multiple frames that we need to render anyway!

This post will outline what it took for me to get this technique into [Flex](https://ajweeks.com), and explain the basics as I go. This is not intended as a tutorial, just as a basic explanation of the technique.

The basic principle is so simple it's deceiving. Jitter the view matrix every frame by a small amount and blend the current frame with the previous one. Done.

[](ground-truth.png)
An alias-free image!

Unfortunately not quite.

In a completely static scene with a static camera, this is enough. After a few frames, the resulting image will converge to the "ground truth" (the "perfect" image, containing no aliasing). But what game have you ever played where nothing moves? When motion is introduced to this na√Øve implementation, massive ghosting artifacts occur.

[](ghosting-gif.gif)

Clearly this needs to be addressed. The simplest fix we can do is to take into account the camera's motion into account since it will affect every pixel, and in a consistent way. If we pass in the previous frame's view-projection matrix, we can see where the current fragment would have been last frame on screen, and sample there instead. This isn't perfect because things can become occluded between two frames, or come from off-screen, but it does help in the majority of cases.

[](reprojected.gif)
Here we "re-project" the current fragments to find a better sample which takes into account camera motion.

There's still a lot of artifacting going on here, but luckily some clever people have arrived at the scene before us! There's two widely-used modifications we can make to our shader to greatly reduce these artifacts. Firstly, after sampling the history buffer we can see how different that colour is from the current frame's. If it's wildly different, we reject the sample entirely and pretend like we didn't sample it. This is referred to as "neighborhood clamping".

[](neighborhood-clipping.gif)

Secondly,

I also attempted to reject samples based on the delta screen-space UV between the current fragment being shaded and the sampled history buffer location, but it quickly became apparent that this technique is flawed since it sees camera motion as a basis to reject, and we still want AA when the camera moves as that's how games are most of the time.

This is great, but if we have any fast moving objects in the scene, the camera "reprojection" won't give us a good sample point. The other techniques (neighborhood clamping, clipping) might be enough, but they also are then no longer anti-aliased. This might be fine, aliasing is hard to see on moving objects anyway. Additionally, if you have any kind of motion blur effect, that will likely hide aliasing completely. Keep in mind that many players disable motion blur however.

But if after all that you want smoother looking moving objects (maybe you're making a film?) there's a solution - per-object velocity tracking. If you have per-object motion blur, then you've got this already! If not, here's how you might do a basic implementation.

Each object can store its previous model matrix, and in a render pass before the temporal resolve you can calculate the screen-space difference between the previous frame's fragment coordinate and the current's. If calculating this per-pixel is showing as being too expensive, it can also be done per-vertex for quite large savings and very little visual difference.

[](per-obj-motion-uvs.png)

It should be noted that deformable objects are not handled by this (swaying vegetation, skinned meshes, etc.). They can be handled, but at a slightly higher cost and more complexity.

With a velocity buffer at hand, your TAA resolve pass simply needs to sample it at the current fragment's UV coordinate, and add the value found there to the coordinate you'll sample the history buffer at. Stationary objects will have an offset of 0 here. TAA and motion blur are kind of like siblings, there's only a few lines that differ between the techniques.

And that's all! Overall temporal anti-aliasing is straightforward, and almost all of the implementation work will be in getting rid of ghosting. I hope this helped explain the basic concept! If you want to implement the technique yourself I'd suggest reading through the sources linked below. My implementation (as ever) lives on GitHub, you can reference it here: https://github.com/ajweeks/Flex.

[](final-results.gif)


### References
